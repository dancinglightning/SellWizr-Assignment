{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# SQL-R1: Text-to-SQL RL Training on Kaggle\n",
                "\n",
                "**Requirements**: Kaggle GPU Runtime (T4 16GB)\n",
                "\n",
                "## Overview\n",
                "- **Paper**: SQL-R1: Training Natural Language to SQL Reasoning Model By Reinforcement Learning\n",
                "- **Algorithm**: GRPO (Group Relative Policy Optimization)\n",
                "- **Model**: Qwen2.5-Coder-3B-Instruct"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Environment Setup\n",
                "\n",
                "⚠️ **IMPORTANT**: After running the installation cell, you MUST restart the kernel before continuing!"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!nvidia-smi"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Step 1: Install dependencies\n",
                "# After this cell completes, RESTART THE KERNEL (Runtime -> Restart runtime)\n",
                "\n",
                "!pip install vllm==0.6.3 ray transformers accelerate --quiet\n",
                "!pip install wandb sqlparse func_timeout nltk ijson --quiet\n",
                "!pip install hydra-core omegaconf --quiet\n",
                "!pip install flash-attn --no-build-isolation --quiet\n",
                "\n",
                "# Clone SQL-R1\n",
                "import os\n",
                "if not os.path.exists('SellWizr-Assignment'):\n",
                "    !git clone https://github.com/dancinglightning/SellWizr-Assignment.git\n",
                "\n",
                "# Install verl\n",
                "%cd SellWizr-Assignment/SQL-R1\n",
                "!pip install -e . --quiet\n",
                "\n",
                "print(\"\\n\" + \"=\"*60)\n",
                "print(\"INSTALLATION COMPLETE!\")\n",
                "print(\"Please RESTART THE KERNEL now: Runtime -> Restart runtime\")\n",
                "print(\"Then skip this cell and run the next one.\")\n",
                "print(\"=\"*60)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Step 2: Run this cell AFTER kernel restart\n",
                "# This cell sets up the working directory after restart\n",
                "\n",
                "import os\n",
                "os.chdir('/kaggle/working/SellWizr-Assignment/SQL-R1')\n",
                "print(f\"Working directory: {os.getcwd()}\")\n",
                "\n",
                "import torch\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "\n",
                "print(f\"PyTorch: {torch.__version__}\")\n",
                "print(f\"NumPy: {np.__version__}\")\n",
                "print(f\"Pandas: {pd.__version__}\")\n",
                "print(f\"CUDA: {torch.cuda.is_available()}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Download Databases"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import sqlite3\n",
                "import shutil\n",
                "\n",
                "# Create directories\n",
                "os.makedirs('data/NL2SQL/SynSQL-2.5M/databases', exist_ok=True)\n",
                "os.makedirs('data/spider/database', exist_ok=True)\n",
                "\n",
                "synsql_db_path = 'data/NL2SQL/SynSQL-2.5M/databases'\n",
                "spider_db_path = 'data/spider/database'\n",
                "\n",
                "# Create test databases for reward function\n",
                "test_schemas = {\n",
                "    'concert_singer': [\n",
                "        'CREATE TABLE singer (singer_id INT PRIMARY KEY, name TEXT, country TEXT, age INT)',\n",
                "        'CREATE TABLE concert (concert_id INT PRIMARY KEY, concert_name TEXT, year INT)'\n",
                "    ],\n",
                "    'pets_1': [\n",
                "        'CREATE TABLE pets (pet_id INT PRIMARY KEY, pet_type TEXT, pet_age INT)',\n",
                "        'CREATE TABLE owners (owner_id INT PRIMARY KEY, name TEXT, age INT)'\n",
                "    ],\n",
                "    'employee_hire_evaluation': [\n",
                "        'CREATE TABLE employees (employee_id INT PRIMARY KEY, name TEXT, department TEXT, salary INT)',\n",
                "        'CREATE TABLE evaluations (eval_id INT PRIMARY KEY, employee_id INT, score INT)'\n",
                "    ],\n",
                "    'world_1': [\n",
                "        'CREATE TABLE country (code TEXT PRIMARY KEY, name TEXT, continent TEXT, population INT)',\n",
                "        'CREATE TABLE city (id INT PRIMARY KEY, name TEXT, country_code TEXT, population INT)'\n",
                "    ]\n",
                "}\n",
                "\n",
                "for db_name, schemas in test_schemas.items():\n",
                "    for base_path in [spider_db_path, synsql_db_path]:\n",
                "        db_dir = f'{base_path}/{db_name}'\n",
                "        os.makedirs(db_dir, exist_ok=True)\n",
                "        db_file = f'{db_dir}/{db_name}.sqlite'\n",
                "        \n",
                "        conn = sqlite3.connect(db_file)\n",
                "        for schema in schemas:\n",
                "            conn.execute(schema)\n",
                "        conn.commit()\n",
                "        conn.close()\n",
                "\n",
                "print(f\"Created {len(test_schemas)} databases!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Download Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from huggingface_hub import snapshot_download\n",
                "import os\n",
                "\n",
                "MODEL_NAME = \"Qwen/Qwen2.5-Coder-3B-Instruct\"\n",
                "MODEL_PATH = \"models/Qwen2.5-Coder-3B-Instruct\"\n",
                "\n",
                "if not os.path.exists(MODEL_PATH):\n",
                "    print(f\"Downloading {MODEL_NAME}...\")\n",
                "    snapshot_download(repo_id=MODEL_NAME, local_dir=MODEL_PATH, local_dir_use_symlinks=False)\n",
                "    print(\"Done!\")\n",
                "else:\n",
                "    print(\"Model exists!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Check Training Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "\n",
                "train_df = pd.read_parquet('example_data/train.parquet')\n",
                "print(f\"Training samples: {len(train_df)}\")\n",
                "print(f\"Columns: {train_df.columns.tolist()}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. RL Training Config"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "os.environ['VLLM_ATTENTION_BACKEND'] = 'XFORMERS'\n",
                "os.environ['TOKENIZERS_PARALLELISM'] = 'false'\n",
                "\n",
                "TRAIN_CONFIG = {\n",
                "    'data.train_files': 'example_data/train.parquet',\n",
                "    'data.val_files': 'example_data/test.parquet',\n",
                "    'data.train_batch_size': 2,\n",
                "    'data.val_batch_size': 2,\n",
                "    'data.max_prompt_length': 1024,\n",
                "    'data.max_response_length': 512,\n",
                "    'actor_rollout_ref.model.path': 'models/Qwen2.5-Coder-3B-Instruct',\n",
                "    'actor_rollout_ref.model.enable_gradient_checkpointing': True,\n",
                "    'actor_rollout_ref.actor.ppo_mini_batch_size': 2,\n",
                "    'actor_rollout_ref.actor.ppo_micro_batch_size': 1,\n",
                "    'actor_rollout_ref.actor.fsdp_config.param_offload': True,\n",
                "    'actor_rollout_ref.actor.fsdp_config.grad_offload': True,\n",
                "    'actor_rollout_ref.actor.fsdp_config.optimizer_offload': True,\n",
                "    'actor_rollout_ref.actor.optim.lr': '1e-6',\n",
                "    'actor_rollout_ref.actor.use_kl_loss': True,\n",
                "    'actor_rollout_ref.actor.kl_loss_coef': 0.001,\n",
                "    'actor_rollout_ref.actor.kl_loss_type': 'low_var_kl',\n",
                "    'actor_rollout_ref.rollout.name': 'vllm',\n",
                "    'actor_rollout_ref.rollout.tensor_model_parallel_size': 1,\n",
                "    'actor_rollout_ref.rollout.gpu_memory_utilization': 0.3,\n",
                "    'actor_rollout_ref.rollout.n': 4,\n",
                "    'actor_rollout_ref.rollout.temperature': 1.0,\n",
                "    'actor_rollout_ref.rollout.log_prob_micro_batch_size': 8,\n",
                "    'actor_rollout_ref.ref.fsdp_config.param_offload': True,\n",
                "    'actor_rollout_ref.ref.log_prob_micro_batch_size': 8,\n",
                "    'algorithm.adv_estimator': 'grpo',\n",
                "    'algorithm.kl_ctrl.kl_coef': 0.001,\n",
                "    'trainer.n_gpus_per_node': 1,\n",
                "    'trainer.nnodes': 1,\n",
                "    'trainer.total_epochs': 1,\n",
                "    'trainer.save_freq': 50,\n",
                "    'trainer.test_freq': 25,\n",
                "    'trainer.critic_warmup': 0,\n",
                "    'trainer.logger': \"['console']\",\n",
                "    'trainer.project_name': 'SQL-R1-Kaggle',\n",
                "    'trainer.experiment_name': '3B-T4-GRPO',\n",
                "    'trainer.default_local_dir': 'logs/kaggle_run',\n",
                "}\n",
                "\n",
                "cmd_args = ' '.join([f\"{k}={v}\" for k, v in TRAIN_CONFIG.items()])\n",
                "print(\"Config ready!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Run training\n",
                "!python -m verl.trainer.main_ppo {cmd_args}"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Test Reward Function"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from verl.utils.reward_score.synsql import extract_solution\n",
                "\n",
                "test = \"\"\"<|im_start|>assistant\n",
                "<think>Query analysis</think>\n",
                "<answer>```sql\nSELECT * FROM employees\n```</answer>\"\"\"\n",
                "\n",
                "answer, think, _ = extract_solution(test)\n",
                "print(f\"Answer: {answer}\")\n",
                "print(f\"Think: {think}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!nvidia-smi"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "accelerator": "GPU"
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
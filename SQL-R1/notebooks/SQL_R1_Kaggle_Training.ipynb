{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# SQL-R1: Text-to-SQL RL Training on Kaggle\n",
                "\n",
                "This notebook implements RL training for Text-to-SQL using the SQL-R1 approach with GRPO algorithm.\n",
                "\n",
                "**Requirements**: Kaggle GPU Runtime (T4 16GB)\n",
                "\n",
                "## Overview\n",
                "- **Paper**: SQL-R1: Training Natural Language to SQL Reasoning Model By Reinforcement Learning\n",
                "- **Algorithm**: GRPO (Group Relative Policy Optimization)\n",
                "- **Model**: Qwen2.5-Coder-3B-Instruct\n",
                "- **Reward**: Format + Execution Correctness + Result Matching + Length Bonus"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Environment Setup"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Check GPU availability\n",
                "!nvidia-smi\n",
                "!nvidia-smi\n",
                "!cd /\n",
                "!rm -rf /kaggle/working/*\n",
                "!rm -rf ~/.cache/huggingface"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Install dependencies (use Kaggle's pre-installed PyTorch to avoid numpy conflicts)\n",
                "# DO NOT reinstall torch - it breaks numpy compatibility\n",
                "\n",
                "import torch\n",
                "print(f\"PyTorch version: {torch.__version__}\")\n",
                "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
                "\n",
                "# Install RL and inference dependencies\n",
                "!pip install vllm==0.6.3 ray --quiet\n",
                "!pip install transformers accelerate --quiet\n",
                "!pip install wandb sqlparse func_timeout nltk ijson --quiet\n",
                "!pip install hydra-core omegaconf --quiet"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Install flash-attention (may take a few minutes)\n",
                "!pip install flash-attn --no-build-isolation --quiet"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Clone and install SQL-R1 (verl integration)\n",
                "import os\n",
                "if not os.path.exists('SellWizr-Assignment'):\n",
                "    !git clone https://github.com/dancinglightning/SellWizr-Assignment.git\n",
                "%cd SellWizr-Assignment/SQL-R1\n",
                "\n",
                "!pip install -e . --quiet"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Download Databases\n",
                "\n",
                "The reward function requires SQLite databases for SQL execution verification."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import zipfile\n",
                "import shutil\n",
                "\n",
                "# Create data directories\n",
                "os.makedirs('data/NL2SQL/SynSQL-2.5M/databases', exist_ok=True)\n",
                "os.makedirs('data/spider/database', exist_ok=True)\n",
                "\n",
                "print(\"Data directories created!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Download Spider database from Yale's official server\n",
                "import os\n",
                "import zipfile\n",
                "\n",
                "spider_db_path = 'data/spider/database'\n",
                "\n",
                "if not os.path.exists(spider_db_path) or len(os.listdir(spider_db_path)) == 0:\n",
                "    print(\"Downloading Spider dataset...\")\n",
                "    \n",
                "    # Try gdown for Google Drive\n",
                "    !pip install gdown --quiet\n",
                "    !gdown --fuzzy \"https://drive.google.com/uc?id=1TqleXec_OykOYFREKKtschzY29dUcVAQ\" -O data/spider.zip 2>/dev/null || true\n",
                "    \n",
                "    if os.path.exists('data/spider.zip') and os.path.getsize('data/spider.zip') > 10000000:\n",
                "        print(\"Extracting Spider...\")\n",
                "        with zipfile.ZipFile('data/spider.zip', 'r') as zip_ref:\n",
                "            zip_ref.extractall('data/')\n",
                "        \n",
                "        # Find and move database folder\n",
                "        for root, dirs, files in os.walk('data'):\n",
                "            if 'database' in dirs:\n",
                "                src_db = os.path.join(root, 'database')\n",
                "                if src_db != spider_db_path and os.path.isdir(src_db):\n",
                "                    if os.path.exists(spider_db_path):\n",
                "                        shutil.rmtree(spider_db_path)\n",
                "                    shutil.move(src_db, spider_db_path)\n",
                "                    break\n",
                "        print(f\"Spider ready! Found {len(os.listdir(spider_db_path))} databases\")\n",
                "    else:\n",
                "        print(\"Spider download unavailable. Will create test databases.\")\n",
                "else:\n",
                "    print(f\"Spider database exists! Found {len(os.listdir(spider_db_path))} databases\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create test databases (ensures reward function works)\n",
                "import sqlite3\n",
                "import os\n",
                "import shutil\n",
                "\n",
                "synsql_db_path = 'data/NL2SQL/SynSQL-2.5M/databases'\n",
                "spider_db_path = 'data/spider/database'\n",
                "\n",
                "# Copy Spider DBs if they exist\n",
                "if os.path.exists(spider_db_path) and len(os.listdir(spider_db_path)) > 0:\n",
                "    print(\"Copying Spider databases to SynSQL path...\")\n",
                "    for db_name in os.listdir(spider_db_path):\n",
                "        src = os.path.join(spider_db_path, db_name)\n",
                "        dst = os.path.join(synsql_db_path, db_name)\n",
                "        if os.path.isdir(src) and not os.path.exists(dst):\n",
                "            shutil.copytree(src, dst)\n",
                "    print(f\"Copied {len(os.listdir(synsql_db_path))} databases!\")\n",
                "else:\n",
                "    # Create minimal test databases\n",
                "    print(\"Creating test databases...\")\n",
                "    \n",
                "    test_schemas = {\n",
                "        'concert_singer': [\n",
                "            'CREATE TABLE singer (singer_id INT PRIMARY KEY, name TEXT, country TEXT, age INT)',\n",
                "            'CREATE TABLE concert (concert_id INT PRIMARY KEY, concert_name TEXT, year INT)'\n",
                "        ],\n",
                "        'pets_1': [\n",
                "            'CREATE TABLE pets (pet_id INT PRIMARY KEY, pet_type TEXT, pet_age INT)',\n",
                "            'CREATE TABLE owners (owner_id INT PRIMARY KEY, name TEXT, age INT)'\n",
                "        ],\n",
                "        'employee_hire_evaluation': [\n",
                "            'CREATE TABLE employees (employee_id INT PRIMARY KEY, name TEXT, department TEXT, salary INT)',\n",
                "            'CREATE TABLE evaluations (eval_id INT PRIMARY KEY, employee_id INT, score INT)'\n",
                "        ],\n",
                "        'world_1': [\n",
                "            'CREATE TABLE country (code TEXT PRIMARY KEY, name TEXT, continent TEXT, population INT)',\n",
                "            'CREATE TABLE city (id INT PRIMARY KEY, name TEXT, country_code TEXT, population INT)'\n",
                "        ]\n",
                "    }\n",
                "    \n",
                "    for db_name, schemas in test_schemas.items():\n",
                "        for base_path in [spider_db_path, synsql_db_path]:\n",
                "            db_dir = f'{base_path}/{db_name}'\n",
                "            os.makedirs(db_dir, exist_ok=True)\n",
                "            db_file = f'{db_dir}/{db_name}.sqlite'\n",
                "            \n",
                "            conn = sqlite3.connect(db_file)\n",
                "            for schema in schemas:\n",
                "                conn.execute(schema)\n",
                "            conn.commit()\n",
                "            conn.close()\n",
                "    \n",
                "    print(f\"Created {len(test_schemas)} test databases!\")\n",
                "\n",
                "print(f\"\\nTotal databases available: {len(os.listdir(synsql_db_path))}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Download Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from huggingface_hub import snapshot_download\n",
                "import os\n",
                "\n",
                "MODEL_NAME = \"Qwen/Qwen2.5-Coder-3B-Instruct\"\n",
                "MODEL_PATH = \"models/Qwen2.5-Coder-3B-Instruct\"\n",
                "\n",
                "if not os.path.exists(MODEL_PATH):\n",
                "    print(f\"Downloading {MODEL_NAME}...\")\n",
                "    snapshot_download(repo_id=MODEL_NAME, local_dir=MODEL_PATH, local_dir_use_symlinks=False)\n",
                "    print(\"Model downloaded!\")\n",
                "else:\n",
                "    print(\"Model already exists!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Prepare Training Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "\n",
                "# Check training data format\n",
                "train_df = pd.read_parquet('example_data/train.parquet')\n",
                "print(f\"Training samples: {len(train_df)}\")\n",
                "print(f\"Columns: {train_df.columns.tolist()}\")\n",
                "print(\"\\nSample entry:\")\n",
                "print(train_df.iloc[0])"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. RL Training with GRPO\n",
                "\n",
                "### Reward Function\n",
                "| Component | Score | Condition |\n",
                "|-----------|-------|-------|\n",
                "| Format | +1/-1 | Valid `<think>...<answer>` structure |\n",
                "| Execution | +2/-2 | SQL executes without errors |\n",
                "| Result Match | +3/-3 | Query results match gold |\n",
                "| Length Bonus | 0-1.5 | Concise reasoning |"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Set environment variables\n",
                "import os\n",
                "\n",
                "os.environ['VLLM_ATTENTION_BACKEND'] = 'XFORMERS'\n",
                "os.environ['TOKENIZERS_PARALLELISM'] = 'false'\n",
                "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:128'"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Training configuration for Kaggle T4 (16GB)\n",
                "\n",
                "TRAIN_CONFIG = {\n",
                "    'data.train_files': 'example_data/train.parquet',\n",
                "    'data.val_files': 'example_data/test.parquet',\n",
                "    'data.train_batch_size': 2,\n",
                "    'data.val_batch_size': 2,\n",
                "    'data.max_prompt_length': 1024,\n",
                "    'data.max_response_length': 512,\n",
                "    'actor_rollout_ref.model.path': 'models/Qwen2.5-Coder-3B-Instruct',\n",
                "    'actor_rollout_ref.model.enable_gradient_checkpointing': True,\n",
                "    'actor_rollout_ref.actor.ppo_mini_batch_size': 2,\n",
                "    'actor_rollout_ref.actor.ppo_micro_batch_size': 1,\n",
                "    'actor_rollout_ref.actor.fsdp_config.param_offload': True,\n",
                "    'actor_rollout_ref.actor.fsdp_config.grad_offload': True,\n",
                "    'actor_rollout_ref.actor.fsdp_config.optimizer_offload': True,\n",
                "    'actor_rollout_ref.actor.optim.lr': '1e-6',\n",
                "    'actor_rollout_ref.actor.use_kl_loss': True,\n",
                "    'actor_rollout_ref.actor.kl_loss_coef': 0.001,\n",
                "    'actor_rollout_ref.actor.kl_loss_type': 'low_var_kl',\n",
                "    'actor_rollout_ref.rollout.name': 'vllm',\n",
                "    'actor_rollout_ref.rollout.tensor_model_parallel_size': 1,\n",
                "    'actor_rollout_ref.rollout.gpu_memory_utilization': 0.3,\n",
                "    'actor_rollout_ref.rollout.n': 4,\n",
                "    'actor_rollout_ref.rollout.temperature': 1.0,\n",
                "    'actor_rollout_ref.rollout.log_prob_micro_batch_size': 8,\n",
                "    'actor_rollout_ref.ref.fsdp_config.param_offload': True,\n",
                "    'actor_rollout_ref.ref.log_prob_micro_batch_size': 8,\n",
                "    'algorithm.adv_estimator': 'grpo',\n",
                "    'algorithm.kl_ctrl.kl_coef': 0.001,\n",
                "    'trainer.n_gpus_per_node': 1,\n",
                "    'trainer.nnodes': 1,\n",
                "    'trainer.total_epochs': 1,\n",
                "    'trainer.save_freq': 50,\n",
                "    'trainer.test_freq': 25,\n",
                "    'trainer.critic_warmup': 0,\n",
                "    'trainer.logger': \"['console']\",\n",
                "    'trainer.project_name': 'SQL-R1-Kaggle',\n",
                "    'trainer.experiment_name': '3B-T4-GRPO',\n",
                "    'trainer.default_local_dir': 'logs/kaggle_run',\n",
                "}\n",
                "\n",
                "cmd_args = ' '.join([f\"{k}={v}\" for k, v in TRAIN_CONFIG.items()])\n",
                "print(\"Config ready. Run next cell to start training.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Run training\n",
                "train_cmd = f\"python -m verl.trainer.main_ppo {cmd_args}\"\n",
                "print(\"Starting RL training with GRPO...\")\n",
                "!{train_cmd}"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Test Reward Function"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from verl.utils.reward_score.synsql import extract_solution, validate_response_structure\n",
                "\n",
                "test_response = \"\"\"<|im_start|>assistant\n",
                "<think>Analyzing query for employees table.</think>\n",
                "<answer>\n",
                "```sql\n",
                "SELECT * FROM employees\n",
                "```\n",
                "</answer>\"\"\"\n",
                "\n",
                "answer, think, processed = extract_solution(test_response)\n",
                "print(f\"Answer: {answer}\")\n",
                "print(f\"Think: {think}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Check training logs\n",
                "import os\n",
                "log_dir = 'logs/kaggle_run'\n",
                "if os.path.exists(log_dir):\n",
                "    for root, dirs, files in os.walk(log_dir):\n",
                "        print(f\"{root}: {len(files)} files\")\n",
                "else:\n",
                "    print(\"No logs yet.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!nvidia-smi"
            ]
        }
    ],
    "metadata": {
        "accelerator": "GPU",
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.9.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
